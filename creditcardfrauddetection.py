# -*- coding: utf-8 -*-
"""CreditCardFraudDetection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/github/hey-subodh/Credit_Card_Fraud_Detection/blob/main/CreditCardFraudDetection.ipynb
"""

#importing the libraries that are needed in this project

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
import seaborn as sns

#loading the dataset to the pandas data frame

credit_card_data = pd.read_csv('/content/creditcard.csv')

# printing the first data set that is checking the working
# converted this features through principle component data method
credit_card_data.head()

# Gives five data from the last
credit_card_data.tail()

# getting the dataset Information
credit_card_data.info()

#checking the number of missing values in each column
credit_card_data.isnull().sum()

# As we can see that there are some missing values in our data set. therefore we need to handle those missing values.
# two method
# Imputation and dropping
# credit_card_data.shape gives us the number of rows and column in the data set
credit_card_data.shape

""" Central Tendencies:
 1. Mean (Filling:- credit_card_data['col_name'].fillna(credit_card_data['col_name'].mean(),inplace = True))
 2. Median change mean to mode or median, anyone you want to use after checking the chart
 3. Mode

 Dropping Method will be used here
"""

credit_card_data = credit_card_data.dropna(how='any')

credit_card_data.isnull().sum()

#As we can see that we have dropped the missing values that are present in our dataset.
# Now checking the distribution of legit and fraudelent transaction

credit_card_data['Class'].value_counts()

"""As we can see that this dataset is higly unbalanced due to the number of cases 1,0 and we cant feed this model into our ml model. we need to preprocess this data.

0--> Normal Transaction

1--> fraudlent Transaction
"""

#Seperating the data for analysis

legit = credit_card_data[credit_card_data.Class == 0]
fraud = credit_card_data[credit_card_data.Class == 1]

print(legit.shape)
print(fraud.shape)

# Getting the Statistical measure of the data
legit.Amount.describe()

fraud.Amount.describe()

# Comparing the values for both the Transactions
credit_card_data.groupby('Class').mean()

"""We will use Under-Sampling Method

Building the sample dataset containing the similar distribution of normal and fraudelent Transactions(150 total)
"""

legit_sample = legit.sample(n=150)

"""Concatenating the two data frames"""

new_dataset = pd.concat([legit_sample,fraud],axis = 0)
# axis =0 means values will be added row wise 1 means column wise

new_dataset.head()

new_dataset.tail()

# Checking Uniform data
new_dataset['Class'].value_counts()

new_dataset.groupby('Class').mean()

"""Splitting the data into features and targets"""

X = new_dataset.drop(columns='Class',axis =1)
Y = new_dataset['Class']

print(X)

print(Y)

"""Now Splitting the data into training data and testing data"""

# 0.2 means 20% is stored in x_test and rest in y_train
X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size = 0.2,stratify = Y, random_state=2)

print(X.shape,X_train.shape,X_test.shape)

"""Now checking the model Training

Logistic Regression model is used due to binary nature
"""

model = LogisticRegression(max_iter=1000)

# Training the Logistic Regression Model with Training Data
# X_train contains data wil Y_train contains respective labels of data in X_train
model.fit(X_train,Y_train)

"""Now Evaluating the model based on accuracy score

\
"""

# Checking the accuracy of training data
X_train_prediction = model.predict(X_train)
training_data_accuracy = accuracy_score(X_train_prediction,Y_train)

print("Accuracy on the Training Data : ",training_data_accuracy)

# Got an accuracy percentage of 99.16%
# Now checking the accuracy on test data
X_test_prediction = model.predict(X_test)
testing_data_accuracy = accuracy_score(X_test_prediction,Y_test)

print("Accuracy on the Testing Data : ",testing_data_accuracy)

